<html>

  <head>

    <meta charset="UTF-8">

    <title>Audio samples from DSN-VC</title>



  </head>

  <body>

    <article>

      <header>

        <h1>Audio samples from "DSN-VC: One-Shot Voice Conversion by Disentangling Representations with Domain Separation Networks"</h1>

      </header>

    </article>



   

    <div><b>Authors:</b> Siyi Zhou, Minchuan Chen, Yi Xu, Jun Ma, Shaojun Wang, Jing Xiao</div>

    <div><b>Abstract:</b> Most previous works on voice conversion (VC) require either parallel corpora or sufficient training data from target speakers. 

      In this paper, we propose DSN-VC, 

      a one-shot voice conversion model which can perform VC from an arbitrary source speaker to an arbitrary target speaker, 

      and both the source and target speakers do not need to be seen during the training stage. 

      The speaker identities and content representations are disentangled by domain separation networks (DSN). 

      In our proposed model, the content encoder is trained to capture the speaker-independent content representations by a gradient reversal layer and the speaker encoder is used to capture the speaker-specific representations. 

      A phoneme recognition module is introduced to ensure that the valid content information is preserved. 

      Our experiment demonstrates that the proposed DSN-VC model can achieve better results compared with the baseline.</div>

    

    

    

    <div><br/>All the speakers are not seen during training.</div>



  

    






    

